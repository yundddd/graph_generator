{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PyG Dataset\n",
    "\n",
    "This notebook is meant to be run in Google Colab. It uses the output files produced by running `graph_generator` to construct a PyG dataset, where each `torch_geometric.data` object is a graph snapshot of the system simulated by the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StXaRwAATOJM"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YA0X0_Xb5MFk",
    "outputId": "a023a702-e090-4f4f-a50c-958045343903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q0pRshh37Skv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data, Dataset, InMemoryDataset, download_url\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5M65KCjAJMzq"
   },
   "source": [
    "# Connect to Google drive and establish directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-YHniSfJLtR",
    "outputId": "81c9e641-d043-47d3-d2a6-95d1720e4bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wu1ZsrNO9N66"
   },
   "outputs": [],
   "source": [
    "edge_idx_path = '/content/drive/MyDrive/CS224 Project/2024-11-04 data/edge'\n",
    "node_features_path = '/content/drive/MyDrive/CS224 Project/2024-11-04 data/out'\n",
    "fault_label_path = '/content/drive/MyDrive/CS224 Project/2024-11-04 data/fault_label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdelkTeogsbM"
   },
   "source": [
    "## PyG Dataset implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zrQ3yJuoKrGE"
   },
   "outputs": [],
   "source": [
    "FEATURE_DIMENSION = 9\n",
    "TIMESTAMP_FEATURE_INDEX = 3\n",
    "HEALTHY_NODE_LABEL = 0\n",
    "ROOT_CAUSE_NODE_LABEL = 1\n",
    "\n",
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [edge_idx_path, node_features_path, fault_label_path]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def get_edge_index(self, path):\n",
    "      edges = []\n",
    "      with open(path, \"r\") as output:\n",
    "        i = 0\n",
    "        for line in output:\n",
    "          edge = line.strip().split(',')\n",
    "          edges.append([int(edge[0]), int(edge[1])])\n",
    "      return torch.tensor(edges, dtype=torch.long).t().contiguous() # put edges into COO format\n",
    "\n",
    "    def get_node_at_fault(self, path):\n",
    "      node_at_fault, timestamp_of_fault = 0, 0\n",
    "      with open(fault_label_path, \"r\") as output:\n",
    "        ind = 0\n",
    "        for line in output:\n",
    "          node_at_fault, timestamp_of_fault = line.strip().split(',')\n",
    "          ind += 1\n",
    "        assert ind == 1 # there should only be one line in this file\n",
    "      return int(node_at_fault), int(timestamp_of_fault)\n",
    "\n",
    "    def get_node_features(self, node_features_path, fault_label_path):\n",
    "      node_features, node_labels = [], []\n",
    "      node_at_fault, timestamp_of_fault = self.get_node_at_fault(fault_label_path)\n",
    "      with open(node_features_path, \"r\") as output:\n",
    "        for line in output:\n",
    "          items = line.strip().split(',')\n",
    "          features = [list(map(int, items[i + 1 : i + FEATURE_DIMENSION + 1]))\n",
    "                            for i in range(0, len(items), FEATURE_DIMENSION + 1)]\n",
    "          time = max([node[TIMESTAMP_FEATURE_INDEX] for node in features]) # features[node_at_fault][TIMESTAMP_FEATURE_INDEX]\n",
    "          features = torch.tensor(features)\n",
    "          node_features.append(features)\n",
    "          labels = [HEALTHY_NODE_LABEL] * features.shape[0]\n",
    "          if time >= timestamp_of_fault:\n",
    "            labels[node_at_fault] = ROOT_CAUSE_NODE_LABEL\n",
    "          labels = torch.tensor(labels).reshape(features.shape[0], 1)\n",
    "          node_labels.append(labels)\n",
    "      return node_features, node_labels\n",
    "\n",
    "    def process(self):\n",
    "        edge_index = self.get_edge_index(self.raw_paths[0])\n",
    "        node_features_per_graph, node_labels_per_graph = self.get_node_features(self.raw_paths[1], self.raw_paths[2])\n",
    "\n",
    "        data_list = []\n",
    "        for idx, features, labels in zip(range(len(node_features_per_graph)), node_features_per_graph, node_labels_per_graph):\n",
    "          graph_data = Data(x=features, edge_index=edge_index, y=labels)\n",
    "          data_list.append(graph_data)\n",
    "\n",
    "          torch.save(graph_data, '/content/drive/MyDrive/CS224 Project/2024-11-04 data/folder/data_{}.pt'.format(idx))\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ODKi7TzR0Yx",
    "outputId": "dab18cad-b39a-4c45-9c96-5beb704b3aff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5, 9], edge_index=[2, 4], y=[5, 1])\n"
     ]
    }
   ],
   "source": [
    "pyg_dataset= GraphDataset('./graphs')\n",
    "graph_0 = pyg_dataset[0]\n",
    "print(graph_0) # Data(x=[5, 9], edge_index=[2, 4], y=[5, 1])\n",
    "\n",
    "# for graph in pyg_dataset:\n",
    "#   print(graph.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FyzSD6lTSl1"
   },
   "source": [
    "# Load features and edges from output files\n",
    "The following code is scratchwork that was used to inspect files and to test preprocessing logic that is used in the PyG dataset implementation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLUT_199MF6u",
    "outputId": "8f6cef4b-d41f-467f-9224-dcb18afdaea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 2],\n",
      "        [1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "edges = []\n",
    "with open(edge_idx_path, \"r\") as output:\n",
    "  i = 0\n",
    "  for line in output:\n",
    "    edge = line.strip().split(',')\n",
    "    edges.append([int(edge[0]), int(edge[1])])\n",
    "edges = torch.tensor(edges, dtype=torch.long).t().contiguous() # put edges into COO format\n",
    "print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tupdn-hfbSJz",
    "outputId": "838f522f-77f1-4cf5-9461-3422446c5513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20\n"
     ]
    }
   ],
   "source": [
    "node_at_fault, timestamp_of_fault = 0, 0\n",
    "with open(fault_label_path, \"r\") as output:\n",
    "  ind = 0\n",
    "  for line in output:\n",
    "    node_at_fault, timestamp_of_fault = [int(val) for val in line.strip().split(',')]\n",
    "    ind += 1\n",
    "  assert ind == 1 # there should only be one line in this file\n",
    "print(node_at_fault, timestamp_of_fault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5Iq-B6RfKFdB",
    "outputId": "c9096375-60c3-4e23-ae75-3ed832fef0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 10, 0, 2, 0, 1, 0, 1], [1, 3, 0, 0, 0, 0, 0, 0, 0], [1, 3, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0]] 0 0\n",
      "[[0, 1, 10, 0, 2, 0, 1, 0, 1], [1, 3, 0, 0, 0, 0, 0, 0, 0], [1, 3, 0, 0, 3, 2, 0, 1, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0]] 0 0\n",
      "[[0, 1, 10, 0, 2, 0, 1, 0, 1], [1, 3, 0, 0, 0, 0, 0, 0, 0], [1, 3, 0, 0, 3, 2, 0, 1, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 3, 0, 0, 1, 0]] 0 0\n",
      "[[0, 1, 10, 0, 2, 0, 1, 0, 1], [1, 3, 0, 2, 3, 2, 0, 1, 1], [1, 3, 0, 0, 3, 2, 0, 1, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 3, 0, 0, 1, 0]] 0 2\n",
      "[[0, 1, 10, 0, 2, 0, 1, 0, 1], [1, 3, 0, 2, 3, 2, 0, 1, 1], [1, 3, 0, 0, 3, 2, 0, 1, 1], [1, 0, 0, 2, 3, 0, 0, 1, 0], [1, 0, 0, 0, 3, 0, 0, 1, 0]] 0 2\n",
      "[[0, 1, 10, 10, 2, 0, 2, 0, 2], [1, 3, 0, 2, 3, 2, 0, 1, 1], [1, 3, 0, 0, 3, 2, 0, 1, 1], [1, 0, 0, 2, 3, 0, 0, 1, 0], [1, 0, 0, 0, 3, 0, 0, 1, 0]] 10 10\n",
      "[[0, 1, 10, 10, 2, 0, 2, 0, 2], [1, 3, 0, 2, 3, 2, 0, 1, 1], [1, 3, 0, 10, 3, 2, 0, 2, 2], [1, 0, 0, 2, 3, 0, 0, 1, 0], [1, 0, 0, 0, 3, 0, 0, 1, 0]] 10 10\n",
      "[[0, 1, 10, 10, 2, 0, 2, 0, 2], [1, 3, 0, 12, 3, 2, 0, 2, 2], [1, 3, 0, 10, 3, 2, 0, 2, 2], [1, 0, 0, 2, 3, 0, 0, 1, 0], [1, 0, 0, 0, 3, 0, 0, 1, 0]] 10 12\n",
      "[[0, 1, 10, 10, 2, 0, 2, 0, 2], [1, 3, 0, 12, 3, 2, 0, 2, 2], [1, 3, 0, 10, 3, 2, 0, 2, 2], [1, 0, 0, 2, 3, 0, 0, 1, 0], [1, 0, 0, 12, 3, 0, 0, 2, 0]] 10 12\n",
      "[[0, 1, 10, 10, 2, 0, 2, 0, 2], [1, 3, 0, 12, 3, 2, 0, 2, 2], [1, 3, 0, 10, 3, 2, 0, 2, 2], [1, 0, 0, 14, 3, 0, 0, 2, 0], [1, 0, 0, 12, 3, 0, 0, 2, 0]] 10 14\n",
      "[[0, 1, 10, 10, 2, 0, 2, 0, 2], [1, 3, 0, 12, 3, 2, 0, 2, 3], [1, 3, 0, 10, 3, 2, 0, 2, 3], [1, 0, 0, 31, 3, 0, 0, 3, 0], [1, 0, 0, 12, 3, 0, 0, 2, 0]] 10 31\n",
      "[[0, 1, 10, 10, 2, 0, 2, 0, 2], [1, 3, 0, 12, 3, 2, 0, 2, 3], [1, 3, 0, 10, 3, 2, 0, 2, 3], [1, 0, 0, 31, 3, 0, 0, 3, 0], [1, 0, 0, 32, 3, 0, 0, 3, 0]] 10 32\n",
      "[[0, 1, 10, 40, 2, 0, 3, 0, 3], [1, 3, 0, 12, 3, 2, 0, 2, 3], [1, 3, 0, 10, 3, 2, 0, 2, 3], [1, 0, 0, 31, 3, 0, 0, 3, 0], [1, 0, 0, 32, 3, 0, 0, 3, 0]] 40 40\n",
      "[[0, 1, 10, 40, 2, 0, 3, 0, 3], [1, 3, 0, 40, 3, 2, 0, 3, 4], [1, 3, 0, 10, 3, 2, 0, 2, 3], [1, 0, 0, 31, 3, 0, 0, 3, 0], [1, 0, 0, 32, 3, 0, 0, 3, 0]] 40 40\n",
      "[[0, 1, 10, 40, 2, 0, 3, 0, 3], [1, 3, 0, 40, 3, 2, 0, 3, 4], [1, 3, 0, 40, 3, 2, 0, 3, 4], [1, 0, 0, 31, 3, 0, 0, 3, 0], [1, 0, 0, 32, 3, 0, 0, 3, 0]] 40 40\n",
      "[[0, 1, 10, 40, 2, 0, 3, 0, 3], [1, 3, 0, 40, 3, 2, 0, 3, 4], [1, 3, 0, 40, 3, 2, 0, 3, 4], [1, 0, 0, 40, 3, 0, 0, 4, 0], [1, 0, 0, 32, 3, 0, 0, 3, 0]] 40 40\n",
      "[[0, 1, 10, 40, 2, 0, 3, 0, 3], [1, 3, 0, 40, 3, 2, 0, 3, 4], [1, 3, 0, 40, 3, 2, 0, 3, 4], [1, 0, 0, 40, 3, 0, 0, 4, 0], [1, 0, 0, 42, 3, 0, 0, 4, 0]] 40 42\n",
      "[('A', [0, 1, 10, 0, 2, 0, 1, 0, 1]), ('B', [1, 3, 0, 0, 0, 0, 0, 0, 0]), ('C', [1, 3, 0, 0, 0, 0, 0, 0, 0]), ('D', [1, 0, 0, 0, 0, 0, 0, 0, 0]), ('E', [1, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
      "tensor([[ 0,  1, 10,  0,  2,  0,  1,  0,  1],\n",
      "        [ 1,  3,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  3,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "Number of graphs:  17\n",
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n"
     ]
    }
   ],
   "source": [
    "FEATURE_DIMENSION = 9\n",
    "\n",
    "graphs, node_features, node_labels = [], [], []\n",
    "with open(node_features_path, \"r\") as output:\n",
    "  for line in output:\n",
    "    items = line.strip().split(',')\n",
    "    formatted_data = [(items[i],\n",
    "                       list(map(int, items[i + 1 : i + FEATURE_DIMENSION + 1])))\n",
    "                      for i in range(0, len(items), FEATURE_DIMENSION + 1)]\n",
    "    features = [list(map(int, items[i + 1 : i + FEATURE_DIMENSION + 1]))\n",
    "                      for i in range(0, len(items), FEATURE_DIMENSION + 1)]\n",
    "    time = features[node_at_fault][TIMESTAMP_FEATURE_INDEX]\n",
    "    print(features, time, max([node[TIMESTAMP_FEATURE_INDEX] for node in features]))\n",
    "    features = torch.tensor(features)\n",
    "    node_features.append(features)\n",
    "    labels = [1] * features.shape[0]\n",
    "    if time >= timestamp_of_fault:\n",
    "      labels[node_at_fault] = 0\n",
    "    labels = torch.tensor(labels).reshape(features.shape[0], 1)\n",
    "    node_labels.append(labels)\n",
    "    graphs.append(formatted_data)\n",
    "print(graphs[0])\n",
    "print(node_features[0])\n",
    "print(\"Number of graphs: \", len(graphs))\n",
    "\n",
    "import numpy as np\n",
    "NODES_IDX = {}\n",
    "for i in range(len(formatted_data)):\n",
    "  NODES_IDX[formatted_data[i][0]] = i\n",
    "print(NODES_IDX)\n",
    "assert len(list(NODES_IDX.keys())) == len(set(list(NODES_IDX.keys())))\n",
    "assert node_features[0].shape == (len(list(NODES_IDX.keys())), FEATURE_DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Pcrnr5dcdfv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
